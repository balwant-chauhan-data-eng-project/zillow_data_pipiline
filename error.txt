##### challenges i had faced during this projecct #####

 
coundn't establish the connection(while connecting with vs code with ec2)


modulenotfound  error and import error  (importing zillow data to zillow_analytics.py)


  


Broken DAG: [/home/ubuntu/airflow/dags/zillowanalytics.py] Traceback (most recent call last):
  File "/home/ubuntu/airflow/dags/zillowanalytics.py", line 59, in <module>
    load_to_s3=BashOperator(
  File "/usr/local/lib/python3.10/dist-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bash_command'

jinja2.exceptions.TemplateSyntaxError: unexpected '}'

raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 127.




 
LAMBDA_WARNING: Unhandled exception. The most likely cause is an issue in the function code. However, in rare cases, a Lambda runtime update can cause unexpected function behavior. For functions using managed runtimes, runtime updates can be triggered by a function change, or can be applied automatically. To determine if the runtime has been updated, check the runtime version in the INIT_START log entry. If this error correlates with a change in the runtime version, you may be able to mitigate this error by temporarily rolling back to the previous runtime version. For more information, see https://docs.aws.amazon.com/lambda/latest/dg/runtimes-update.html  


 

[ERROR] ClientError: An error occurred (IllegalLocationConstraintException) when calling the CopyObject operation: The ap-south-2 location constraint is incompatible for the region specific endpoint this request was sent to.
Traceback (most recent call last):
  File "/var/task/lambda_function.py", line 19, in lambda_handler
    s3_client.copy_object(Bucket=target_bucket, Key=object_key, CopySource={'Bucket': source_bucket, 'Key': object_key})
  File "/var/lang/lib/python3.12/site-packages/botocore/client.py", line 553, in _api_call
    return self._make_api_call(operation_name, kwargs)
  File "/var/lang/lib/python3.12/site-packages/botocore/client.py", line 1009, in _make_api_call
    raise error_class(parsed_response, operation_name)



[ERROR] WaiterError: Waiter ObjectExists failed: An error occurred (403): Forbidden
Traceback (most recent call last):
  File "/var/task/lambda_function.py", line 17, in lambda_handler
    waiter.wait(Bucket=source_bucket, Key=object_key)
  File "/var/lang/lib/python3.12/site-packages/botocore/waiter.py", line 55, in wait
    Waiter.wait(self, **kwargs)
  File "/var/lang/lib/python3.12/site-packages/botocore/waiter.py", line 357, in wait
    raise WaiterError(




 
redshift_connector.error.ProgrammingError: {'S': 'ERROR', 'C': 'XX000', 'M': "Load into table 'zillowdata' failed.  Check 'stl_load_errors' system table for details.", 'F': '../src/pg/src/backend/commands/commands_copy.c', 'L': '737', 'R': 'CheckMaxRowError'}
 
[2024-04-15, 15:53:26 UTC] {standard_task_runner.py:107} ERROR - Failed to execute job 454 for task tsk_transfer_s3_to_redshift ({'S': 'ERROR', 'C': 'XX000', 'M': "Load into table 'zillowdata' failed.  Check 'stl_load_errors' system table for details.", 'F': '../src/pg/src/backend/commands/commands_copy.c', 'L': '737', 'R': 'CheckMaxRowError'}; 3009)
 
